{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression , LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Mudassir Raza/Desktop/AI Project/Data-set food impact on indian people/food_impact_india.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {}\n",
    "for column in data.select_dtypes(include=[object]).columns:\n",
    "    label_encoder[column]=LabelEncoder()\n",
    "    data[column]=label_encoder[column].fit_transform(data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17686, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        Person_ID  Age  Gender  Region  Diet_Type  Primary_Cuisine  \\\n",
       "0              1   56       0       1          2                1   \n",
       "1              2   69       1       0          2                3   \n",
       "2              3   46       1       3          2                2   \n",
       "3              4   32       0       4          1                3   \n",
       "4              5   60       1       1          0                1   \n",
       "...          ...  ...     ...     ...        ...              ...   \n",
       "17681      17682   61       1       2          0                3   \n",
       "17682      17683   31       1       3          2                6   \n",
       "17683      17684   32       0       1          2                3   \n",
       "17684      17685   33       2       4          0                1   \n",
       "17685      17686   19       1       3          0                0   \n",
       "\n",
       "       Spice_Level  Daily_Calorie_Intake  Health_Impact  Common_Diseases  \\\n",
       "0                0                  2768              2                1   \n",
       "1                1                  3005              2                3   \n",
       "2                2                  3416              2                1   \n",
       "3                2                  1572              1                4   \n",
       "4                2                  2539              0                1   \n",
       "...            ...                   ...            ...              ...   \n",
       "17681            2                  3363              2                0   \n",
       "17682            1                  1911              0                4   \n",
       "17683            1                  1942              2                1   \n",
       "17684            0                  1778              0                4   \n",
       "17685            1                  3253              2                4   \n",
       "\n",
       "       Exercise_Level   BMI  Food_Frequency  Sugar_Intake  Salt_Intake  \\\n",
       "0                   2  37.3               5             1            0   \n",
       "1                   1  38.4               3             1            2   \n",
       "2                   2  19.6               4             0            1   \n",
       "3                   1  32.5               5             1            1   \n",
       "4                   1  30.4               4             0            2   \n",
       "...               ...   ...             ...           ...          ...   \n",
       "17681               1  20.1               2             2            0   \n",
       "17682               2  27.1               5             1            2   \n",
       "17683               1  29.1               2             1            2   \n",
       "17684               1  33.5               3             2            0   \n",
       "17685               2  19.6               1             2            2   \n",
       "\n",
       "       Health_Score  \n",
       "0                30  \n",
       "1                95  \n",
       "2                86  \n",
       "3                81  \n",
       "4                37  \n",
       "...             ...  \n",
       "17681            27  \n",
       "17682            58  \n",
       "17683            59  \n",
       "17684            20  \n",
       "17685            28  \n",
       "\n",
       "[17686 rows x 16 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Region</th>\n",
       "      <th>Diet_Type</th>\n",
       "      <th>Primary_Cuisine</th>\n",
       "      <th>Spice_Level</th>\n",
       "      <th>Daily_Calorie_Intake</th>\n",
       "      <th>Health_Impact</th>\n",
       "      <th>Common_Diseases</th>\n",
       "      <th>Exercise_Level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Food_Frequency</th>\n",
       "      <th>Sugar_Intake</th>\n",
       "      <th>Salt_Intake</th>\n",
       "      <th>Health_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2768</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3005</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person_ID  Age  Gender  Region  Diet_Type  Primary_Cuisine  Spice_Level  \\\n",
       "0          1   56       0       1          2                1            0   \n",
       "1          2   69       1       0          2                3            1   \n",
       "\n",
       "   Daily_Calorie_Intake  Health_Impact  Common_Diseases  Exercise_Level   BMI  \\\n",
       "0                  2768              2                1               2  37.3   \n",
       "1                  3005              2                3               1  38.4   \n",
       "\n",
       "   Food_Frequency  Sugar_Intake  Salt_Intake  Health_Score  \n",
       "0               5             1            0            30  \n",
       "1               3             1            2            95  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Health_Score' , axis=1)\n",
    "y = data['Health_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y , test_size=0.2 , random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "lin_model = LinearRegression()\n",
    "log_model = LogisticRegression()\n",
    "tree_model = DecisionTreeClassifier()\n",
    "svm_model = SVC()\n",
    "random_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navie Bayse\n",
      "Accuracy:1.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.02      0.06      0.03        34\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        37\n",
      "          11       0.00      0.00      0.00        44\n",
      "          12       0.02      0.04      0.02        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.00      0.00      0.00        37\n",
      "          18       0.02      0.06      0.03        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.02      0.05      0.03        41\n",
      "          22       0.06      0.02      0.03        44\n",
      "          23       0.00      0.00      0.00        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.00      0.00      0.00        42\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.00      0.00      0.00        40\n",
      "          28       0.02      0.03      0.02        40\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.00      0.00      0.00        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.00      0.00      0.00        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.01      0.03      0.02        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.01      0.03      0.02        29\n",
      "          40       0.00      0.00      0.00        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.00      0.00      0.00        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.00      0.00      0.00        36\n",
      "          45       0.00      0.00      0.00        34\n",
      "          46       0.00      0.00      0.00        47\n",
      "          47       0.00      0.00      0.00        40\n",
      "          48       0.01      0.03      0.02        37\n",
      "          49       0.02      0.02      0.02        41\n",
      "          50       0.02      0.03      0.02        37\n",
      "          51       0.02      0.05      0.03        38\n",
      "          52       0.00      0.00      0.00        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.03      0.03      0.03        36\n",
      "          55       0.00      0.00      0.00        31\n",
      "          56       0.00      0.00      0.00        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.00      0.00      0.00        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.00      0.00      0.00        36\n",
      "          63       0.00      0.00      0.00        38\n",
      "          64       0.05      0.03      0.04        34\n",
      "          65       0.00      0.00      0.00        36\n",
      "          66       0.00      0.00      0.00        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.01      0.03      0.02        39\n",
      "          69       0.05      0.03      0.04        32\n",
      "          70       0.03      0.07      0.05        45\n",
      "          71       0.04      0.03      0.03        32\n",
      "          72       0.01      0.07      0.02        42\n",
      "          73       0.00      0.00      0.00        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.02      0.06      0.03        33\n",
      "          76       0.01      0.03      0.02        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.00      0.00      0.00        30\n",
      "          79       0.00      0.00      0.00        29\n",
      "          80       0.00      0.00      0.00        35\n",
      "          81       0.00      0.00      0.00        40\n",
      "          82       0.07      0.03      0.04        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.10      0.03      0.04        35\n",
      "          85       0.10      0.05      0.07        39\n",
      "          86       0.00      0.00      0.00        28\n",
      "          87       0.00      0.00      0.00        41\n",
      "          88       0.00      0.00      0.00        38\n",
      "          89       0.00      0.00      0.00        29\n",
      "          90       0.00      0.00      0.00        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.00      0.00      0.00        38\n",
      "          93       0.02      0.11      0.04        37\n",
      "          94       0.00      0.00      0.00        36\n",
      "          95       0.00      0.00      0.00        37\n",
      "          96       0.05      0.03      0.03        38\n",
      "          97       0.00      0.00      0.00        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.01      3538\n",
      "   macro avg       0.01      0.01      0.01      3538\n",
      "weighted avg       0.01      0.01      0.01      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "nb_model.fit(X_train , y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print('Navie Bayse')\n",
    "print(f'Accuracy:{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Accuracy :1.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.00      0.00      0.00        34\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        37\n",
      "          11       0.00      0.00      0.00        44\n",
      "          12       0.00      0.00      0.00        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.00      0.00      0.00        37\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.00      0.00      0.00        41\n",
      "          22       0.00      0.00      0.00        44\n",
      "          23       0.00      0.00      0.00        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.00      0.00      0.00        42\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.00      0.00      0.00        40\n",
      "          28       0.00      0.00      0.00        40\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.00      0.00      0.00        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.00      0.00      0.00        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.00      0.00      0.00        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.00      0.00      0.00        29\n",
      "          40       0.00      0.00      0.00        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.00      0.00      0.00        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.00      0.00      0.00        36\n",
      "          45       0.00      0.00      0.00        34\n",
      "          46       0.00      0.00      0.00        47\n",
      "          47       0.00      0.00      0.00        40\n",
      "          48       0.00      0.00      0.00        37\n",
      "          49       0.03      0.10      0.04        41\n",
      "          50       0.01      0.27      0.02        37\n",
      "          51       0.01      0.42      0.02        38\n",
      "          52       0.01      0.28      0.03        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.00      0.00      0.00        31\n",
      "          56       0.00      0.00      0.00        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.00      0.00      0.00        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.00      0.00      0.00        36\n",
      "          63       0.00      0.00      0.00        38\n",
      "          64       0.00      0.00      0.00        34\n",
      "          65       0.00      0.00      0.00        36\n",
      "          66       0.00      0.00      0.00        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.00      0.00      0.00        39\n",
      "          69       0.00      0.00      0.00        32\n",
      "          70       0.00      0.00      0.00        45\n",
      "          71       0.00      0.00      0.00        32\n",
      "          72       0.00      0.00      0.00        42\n",
      "          73       0.00      0.00      0.00        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.00      0.00      0.00        33\n",
      "          76       0.00      0.00      0.00        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.00      0.00      0.00        30\n",
      "          79       0.00      0.00      0.00        29\n",
      "          80       0.00      0.00      0.00        35\n",
      "          81       0.00      0.00      0.00        40\n",
      "          82       0.00      0.00      0.00        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.00      0.00      0.00        35\n",
      "          85       0.00      0.00      0.00        39\n",
      "          86       0.00      0.00      0.00        28\n",
      "          87       0.00      0.00      0.00        41\n",
      "          88       0.00      0.00      0.00        38\n",
      "          89       0.00      0.00      0.00        29\n",
      "          90       0.00      0.00      0.00        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.00      0.00      0.00        38\n",
      "          93       0.00      0.00      0.00        37\n",
      "          94       0.00      0.00      0.00        36\n",
      "          95       0.00      0.00      0.00        37\n",
      "          96       0.00      0.00      0.00        38\n",
      "          97       0.00      0.00      0.00        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.01      3538\n",
      "   macro avg       0.00      0.01      0.00      3538\n",
      "weighted avg       0.00      0.01      0.00      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lin_model.fit(X_train, y_train)\n",
    "y_pred = lin_model.predict(X_test)\n",
    "# Convert predictions to integer values for accuracy calculation\n",
    "# .round() round the integer to nearest value\n",
    "# .astype(int) convert rounded value to integer\n",
    "y_pred_int = y_pred.round().astype(int)\n",
    "accuracy = accuracy_score(y_test , y_pred_int)\n",
    "print('Linear Regression')\n",
    "print(f'Accuracy :{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuarcy :1.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.04      0.06      0.05        34\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        37\n",
      "          11       0.00      0.00      0.00        44\n",
      "          12       0.00      0.00      0.00        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.02      0.14      0.03        37\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.00      0.00      0.00        41\n",
      "          22       0.00      0.00      0.00        44\n",
      "          23       0.02      0.15      0.03        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.00      0.00      0.00        42\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.00      0.00      0.00        40\n",
      "          28       0.00      0.00      0.00        40\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.00      0.00      0.00        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.00      0.00      0.00        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.00      0.00      0.00        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.00      0.00      0.00        29\n",
      "          40       0.01      0.03      0.01        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.00      0.00      0.00        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.00      0.00      0.00        36\n",
      "          45       0.02      0.03      0.03        34\n",
      "          46       0.00      0.00      0.00        47\n",
      "          47       0.00      0.00      0.00        40\n",
      "          48       0.00      0.00      0.00        37\n",
      "          49       0.00      0.00      0.00        41\n",
      "          50       0.01      0.14      0.03        37\n",
      "          51       0.00      0.00      0.00        38\n",
      "          52       0.00      0.00      0.00        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.01      0.13      0.02        31\n",
      "          56       0.02      0.15      0.03        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.00      0.00      0.00        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.00      0.00      0.00        36\n",
      "          63       0.00      0.00      0.00        38\n",
      "          64       0.00      0.00      0.00        34\n",
      "          65       0.00      0.00      0.00        36\n",
      "          66       0.02      0.15      0.03        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.00      0.00      0.00        39\n",
      "          69       0.00      0.00      0.00        32\n",
      "          70       0.00      0.00      0.00        45\n",
      "          71       0.00      0.00      0.00        32\n",
      "          72       0.02      0.17      0.03        42\n",
      "          73       0.00      0.00      0.00        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.01      0.15      0.02        33\n",
      "          76       0.00      0.00      0.00        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.00      0.00      0.00        30\n",
      "          79       0.00      0.00      0.00        29\n",
      "          80       0.00      0.00      0.00        35\n",
      "          81       0.00      0.00      0.00        40\n",
      "          82       0.00      0.00      0.00        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.00      0.00      0.00        35\n",
      "          85       0.00      0.00      0.00        39\n",
      "          86       0.00      0.00      0.00        28\n",
      "          87       0.00      0.00      0.00        41\n",
      "          88       0.00      0.00      0.00        38\n",
      "          89       0.00      0.00      0.00        29\n",
      "          90       0.00      0.00      0.00        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.00      0.00      0.00        38\n",
      "          93       0.00      0.00      0.00        37\n",
      "          94       0.00      0.00      0.00        36\n",
      "          95       0.00      0.00      0.00        37\n",
      "          96       0.00      0.00      0.00        38\n",
      "          97       0.00      0.00      0.00        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.01      3538\n",
      "   macro avg       0.00      0.01      0.00      3538\n",
      "weighted avg       0.00      0.01      0.00      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "log_model.fit(X_train , y_train)\n",
    "y_pred= log_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print('Logistic Regression')\n",
    "print(f'Accuarcy :{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree model\n",
      "accuracy:0.96%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.00      0.00      0.00        34\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.03      0.03      0.03        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.04      0.03      0.03        37\n",
      "          11       0.02      0.02      0.02        44\n",
      "          12       0.00      0.00      0.00        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.03      0.03      0.03        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.00      0.00      0.00        37\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.00      0.00      0.00        41\n",
      "          22       0.02      0.02      0.02        44\n",
      "          23       0.00      0.00      0.00        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.02      0.02      0.02        42\n",
      "          26       0.03      0.04      0.03        25\n",
      "          27       0.00      0.00      0.00        40\n",
      "          28       0.00      0.00      0.00        40\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.00      0.00      0.00        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.00      0.00      0.00        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.00      0.00      0.00        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.03      0.03      0.03        29\n",
      "          40       0.00      0.00      0.00        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.00      0.00      0.00        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.03      0.03      0.03        36\n",
      "          45       0.03      0.03      0.03        34\n",
      "          46       0.00      0.00      0.00        47\n",
      "          47       0.00      0.00      0.00        40\n",
      "          48       0.00      0.00      0.00        37\n",
      "          49       0.00      0.00      0.00        41\n",
      "          50       0.00      0.00      0.00        37\n",
      "          51       0.03      0.03      0.03        38\n",
      "          52       0.03      0.03      0.03        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.06      0.06      0.06        31\n",
      "          56       0.00      0.00      0.00        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.00      0.00      0.00        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.03      0.03      0.03        36\n",
      "          63       0.03      0.03      0.03        38\n",
      "          64       0.02      0.03      0.03        34\n",
      "          65       0.00      0.00      0.00        36\n",
      "          66       0.00      0.00      0.00        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.03      0.03      0.03        39\n",
      "          69       0.02      0.03      0.03        32\n",
      "          70       0.05      0.04      0.05        45\n",
      "          71       0.00      0.00      0.00        32\n",
      "          72       0.00      0.00      0.00        42\n",
      "          73       0.03      0.03      0.03        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.02      0.03      0.02        33\n",
      "          76       0.02      0.03      0.02        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.00      0.00      0.00        30\n",
      "          79       0.06      0.07      0.07        29\n",
      "          80       0.04      0.03      0.03        35\n",
      "          81       0.04      0.03      0.03        40\n",
      "          82       0.00      0.00      0.00        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.00      0.00      0.00        35\n",
      "          85       0.00      0.00      0.00        39\n",
      "          86       0.02      0.04      0.03        28\n",
      "          87       0.00      0.00      0.00        41\n",
      "          88       0.00      0.00      0.00        38\n",
      "          89       0.00      0.00      0.00        29\n",
      "          90       0.03      0.04      0.03        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.02      0.03      0.02        38\n",
      "          93       0.05      0.03      0.03        37\n",
      "          94       0.00      0.00      0.00        36\n",
      "          95       0.03      0.03      0.03        37\n",
      "          96       0.00      0.00      0.00        38\n",
      "          97       0.04      0.04      0.04        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.01      3538\n",
      "   macro avg       0.01      0.01      0.01      3538\n",
      "weighted avg       0.01      0.01      0.01      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model.fit(X_train , y_train)\n",
    "y_pred= tree_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print(\"Tree model\")\n",
    "print(f'accuracy:{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy:1.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.00      0.00      0.00        34\n",
      "           6       0.02      0.04      0.02        27\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.04      0.02      0.03        50\n",
      "          10       0.00      0.00      0.00        37\n",
      "          11       0.00      0.00      0.00        44\n",
      "          12       0.00      0.00      0.00        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.04      0.08      0.06        37\n",
      "          18       0.02      0.03      0.02        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.03      0.03      0.03        34\n",
      "          21       0.00      0.00      0.00        41\n",
      "          22       0.00      0.00      0.00        44\n",
      "          23       0.00      0.00      0.00        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.00      0.00      0.00        42\n",
      "          26       0.02      0.04      0.03        25\n",
      "          27       0.03      0.03      0.03        40\n",
      "          28       0.00      0.00      0.00        40\n",
      "          29       0.03      0.03      0.03        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.02      0.03      0.03        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.10      0.12      0.11        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.02      0.03      0.02        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.00      0.00      0.00        29\n",
      "          40       0.03      0.03      0.03        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.04      0.03      0.03        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.03      0.03      0.03        36\n",
      "          45       0.02      0.03      0.03        34\n",
      "          46       0.03      0.02      0.02        47\n",
      "          47       0.03      0.03      0.03        40\n",
      "          48       0.00      0.00      0.00        37\n",
      "          49       0.00      0.00      0.00        41\n",
      "          50       0.02      0.03      0.02        37\n",
      "          51       0.02      0.03      0.02        38\n",
      "          52       0.00      0.00      0.00        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.03      0.03      0.03        31\n",
      "          56       0.00      0.00      0.00        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.04      0.03      0.03        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.00      0.00      0.00        36\n",
      "          63       0.00      0.00      0.00        38\n",
      "          64       0.00      0.00      0.00        34\n",
      "          65       0.03      0.03      0.03        36\n",
      "          66       0.00      0.00      0.00        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.00      0.00      0.00        39\n",
      "          69       0.00      0.00      0.00        32\n",
      "          70       0.00      0.00      0.00        45\n",
      "          71       0.00      0.00      0.00        32\n",
      "          72       0.00      0.00      0.00        42\n",
      "          73       0.05      0.03      0.04        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.00      0.00      0.00        33\n",
      "          76       0.00      0.00      0.00        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.06      0.07      0.06        30\n",
      "          79       0.00      0.00      0.00        29\n",
      "          80       0.00      0.00      0.00        35\n",
      "          81       0.00      0.00      0.00        40\n",
      "          82       0.06      0.06      0.06        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.03      0.03      0.03        35\n",
      "          85       0.03      0.03      0.03        39\n",
      "          86       0.00      0.00      0.00        28\n",
      "          87       0.04      0.02      0.03        41\n",
      "          88       0.03      0.03      0.03        38\n",
      "          89       0.03      0.03      0.03        29\n",
      "          90       0.00      0.00      0.00        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.00      0.00      0.00        38\n",
      "          93       0.00      0.00      0.00        37\n",
      "          94       0.03      0.03      0.03        36\n",
      "          95       0.06      0.05      0.06        37\n",
      "          96       0.00      0.00      0.00        38\n",
      "          97       0.00      0.00      0.00        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.01      3538\n",
      "   macro avg       0.01      0.01      0.01      3538\n",
      "weighted avg       0.01      0.01      0.01      3538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_model.fit(X_train , y_train)\n",
    "y_pred=random_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print('Random Forest')\n",
    "print(f'Accuracy:{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:1.53%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        37\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.01      0.18      0.02        34\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        37\n",
      "          11       0.00      0.00      0.00        44\n",
      "          12       0.00      0.00      0.00        28\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        35\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.00      0.00      0.00        37\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        38\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.00      0.00      0.00        41\n",
      "          22       0.00      0.00      0.00        44\n",
      "          23       0.00      0.00      0.00        40\n",
      "          24       0.00      0.00      0.00        27\n",
      "          25       0.00      0.00      0.00        42\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.00      0.00      0.00        40\n",
      "          28       0.00      0.00      0.00        40\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.00      0.00      0.00        44\n",
      "          31       0.00      0.00      0.00        34\n",
      "          32       0.00      0.00      0.00        39\n",
      "          33       0.00      0.00      0.00        32\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        22\n",
      "          37       0.01      0.06      0.01        32\n",
      "          38       0.00      0.00      0.00        35\n",
      "          39       0.00      0.00      0.00        29\n",
      "          40       0.00      0.00      0.00        35\n",
      "          41       0.00      0.00      0.00        37\n",
      "          42       0.00      0.00      0.00        39\n",
      "          43       0.00      0.00      0.00        32\n",
      "          44       0.00      0.00      0.00        36\n",
      "          45       0.00      0.00      0.00        34\n",
      "          46       0.00      0.00      0.00        47\n",
      "          47       0.00      0.00      0.00        40\n",
      "          48       0.00      0.00      0.00        37\n",
      "          49       0.00      0.00      0.00        41\n",
      "          50       0.00      0.00      0.00        37\n",
      "          51       0.00      0.00      0.00        38\n",
      "          52       0.00      0.00      0.00        36\n",
      "          53       0.00      0.00      0.00        33\n",
      "          54       0.00      0.00      0.00        36\n",
      "          55       0.00      0.00      0.00        31\n",
      "          56       0.02      0.48      0.04        46\n",
      "          57       0.00      0.00      0.00        29\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.00      0.00      0.00        44\n",
      "          60       0.00      0.00      0.00        36\n",
      "          61       0.00      0.00      0.00        33\n",
      "          62       0.00      0.00      0.00        36\n",
      "          63       0.00      0.00      0.00        38\n",
      "          64       0.00      0.00      0.00        34\n",
      "          65       0.00      0.00      0.00        36\n",
      "          66       0.00      0.00      0.00        40\n",
      "          67       0.00      0.00      0.00        28\n",
      "          68       0.00      0.00      0.00        39\n",
      "          69       0.00      0.00      0.00        32\n",
      "          70       0.00      0.00      0.00        45\n",
      "          71       0.00      0.00      0.00        32\n",
      "          72       0.02      0.38      0.03        42\n",
      "          73       0.00      0.00      0.00        30\n",
      "          74       0.00      0.00      0.00        33\n",
      "          75       0.02      0.24      0.03        33\n",
      "          76       0.00      0.00      0.00        32\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.00      0.00      0.00        30\n",
      "          79       0.00      0.00      0.00        29\n",
      "          80       0.00      0.00      0.00        35\n",
      "          81       0.00      0.00      0.00        40\n",
      "          82       0.00      0.00      0.00        32\n",
      "          83       0.00      0.00      0.00        38\n",
      "          84       0.00      0.00      0.00        35\n",
      "          85       0.00      0.00      0.00        39\n",
      "          86       0.00      0.00      0.00        28\n",
      "          87       0.00      0.00      0.00        41\n",
      "          88       0.00      0.00      0.00        38\n",
      "          89       0.00      0.00      0.00        29\n",
      "          90       0.00      0.00      0.00        28\n",
      "          91       0.00      0.00      0.00        41\n",
      "          92       0.00      0.00      0.00        38\n",
      "          93       0.00      0.00      0.00        37\n",
      "          94       0.00      0.00      0.00        36\n",
      "          95       0.00      0.00      0.00        37\n",
      "          96       0.00      0.00      0.00        38\n",
      "          97       0.00      0.00      0.00        28\n",
      "          98       0.00      0.00      0.00        27\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.02      3538\n",
      "   macro avg       0.00      0.01      0.00      3538\n",
      "weighted avg       0.00      0.02      0.00      3538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Mudassir Raza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train , y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print('SVM')\n",
    "print(f'accuracy:{accuracy*100:.2f}%')\n",
    "print(classification_report(y_test , y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
